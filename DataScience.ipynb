{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#import xgboost as xgb\n",
    "from IPython.display import display\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "#display(train.head())\n",
    "print('Number of NaN values')\n",
    "#check if there are any missing values\n",
    "#display(pd.isnull(train).sum())\n",
    "#Parsing DT string\n",
    "train['pickup_datetime'] = train['pickup_datetime'].astype(str)\n",
    "dtparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "train['pickup_datetime'] = train['pickup_datetime'].apply(dtparse)\n",
    "train['DOW'] = train['pickup_datetime'].dt.dayofweek\n",
    "train['Hour'] = train['pickup_datetime'].apply(lambda x:x.hour)\n",
    "display(train['pickup_datetime'].describe())\n",
    "display(train.head())\n",
    "\n",
    "from math import radians, sin, cos, sqrt, asin\n",
    "def haversine(columns):\n",
    "  lat1, lon1, lat2, lon2 = columns\n",
    "  R = 6372.8 # Earth radius in kilometers\n",
    "\n",
    "  dLat = radians(lat2 - lat1)\n",
    "  dLon = radians(lon2 - lon1)\n",
    "  lat1 = radians(lat1)\n",
    "  lat2 = radians(lat2)\n",
    "  a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "  c = 2*asin(sqrt(a))\n",
    "\n",
    "  return R * c\n",
    "cols = ['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude']\n",
    "distances = train[cols].apply(\n",
    "    lambda x: haversine(x),axis = 1\n",
    ")\n",
    "train['haversine_distances'] = distances.copy()\n",
    "train.head()\n",
    "\n",
    "lowq,highq = 1,99\n",
    "\n",
    "#Trimming based on outlier distances and durations\n",
    "trip = train['trip_duration']\n",
    "ltrip,rtrip= np.percentile(trip,[lowq,highq])#getting 1 and 99 percentiles\n",
    "print(ltrip,rtrip)\n",
    "train_trimmed = train[trip.between(ltrip,rtrip)]\n",
    "\n",
    "haversine=train['haversine_distances']\n",
    "ltrip,rtrip= np.percentile(haversine,[lowq,highq])\n",
    "print(ltrip,rtrip)\n",
    "\n",
    "train_trimmed = train_trimmed[haversine.between(ltrip,rtrip)]\n",
    "\n",
    "features = train_trimmed[['DOW','Hour','passenger_count','pickup_latitude','pickup_longitude']]\n",
    "target = train_trimmed[['trip_duration']]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    kmeans = pickle.load(open(\"source_kmeans.pickle\", \"rb\"))\n",
    "except:\n",
    "    kmeans = KMeans(n_clusters=20, random_state=0).fit(train_trimmed[['pickup_longitude','pickup_latitude']])\n",
    "    pickle.dump(kmeans, open('source_kmeans.pickle', 'wb'))\n",
    "\n",
    "try:\n",
    "    destkmeans = pickle.load(open(\"dest_kmeans.pickle\", \"rb\"))\n",
    "except:\n",
    "    destkmeans = KMeans(n_clusters=20, random_state=0).fit(train_trimmed[['dropoff_longitude','dropoff_latitude']])\n",
    "    pickle.dump(destkmeans, open('dest_kmeans.pickle', 'wb'))\n",
    "\n",
    "\n",
    "train_trimmed['cluster'] = kmeans.predict(train_trimmed[['pickup_longitude','pickup_latitude']])\n",
    "train_trimmed['dest_cluster'] = destkmeans.predict(train_trimmed[['dropoff_longitude','dropoff_latitude']])\n",
    "\n",
    "\n",
    "import xgboost\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "features = train_trimmed[['DOW','Hour','passenger_count','cluster','dest_cluster','dropoff_latitude','dropoff_longitude','pickup_longitude','pickup_latitude']]\n",
    "target = train_trimmed[['trip_duration']]\n",
    "reg = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "reg.fit(features,target)\n",
    "\n",
    "\n",
    " \n",
    "tdf = pd.read_csv('../input/test.csv')\n",
    "tdf['cluster'] = kmeans.predict(tdf[['pickup_longitude','pickup_latitude']])\n",
    "tdf['dest_cluster'] = destkmeans.predict(tdf[['dropoff_longitude','dropoff_latitude']])\n",
    "tdf.pickup_datetime=pd.to_datetime(tdf.pickup_datetime)\n",
    "#tdf.dropoff_datetime=pd.to_datetime(tdf.dropoff_datetime)\n",
    "tdf['Hour'] = tdf.pickup_datetime.dt.hour\n",
    "\n",
    "tdf['DOW'] = tdf.pickup_datetime.dt.dayofweek\n",
    "tfeatures = tdf[['DOW','Hour','passenger_count','cluster','dest_cluster','dropoff_latitude','dropoff_longitude','pickup_longitude','pickup_latitude']]\n",
    "pred = reg.predict(tfeatures)\n",
    "\n",
    "\n",
    "\n",
    "tdf['trip_duration']=pred.astype(int)\n",
    "out = tdf[['id','trip_duration']]\n",
    "out['trip_duration'].isnull().values.any()\n",
    "out.to_csv('pred_linear_2_clusters.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "print('completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
